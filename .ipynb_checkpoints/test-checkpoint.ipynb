{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"In today’s  highly digital world, online content such as news websites,videos and social media have become a deciding factor in the minds of the general public when it comes to forming opinions on an issue. As people begin to rely on the internet for every trivial task, it is necessary to make sure that misinformation or fake news is detected and filtered from it in order to reduce its negative effects. \n",
    "\n",
    "In recent times, the outbreak of the Covid-19 virus has shown that fake news is a real issue with the harmful potential of spreading faster than the virus itself. It has the ability to manipulate people’s perceptions and is widely used by several politicians to influence large groups of people and even cause social conflicts in order to fulfill personal agendas. These problems make it necessary to eliminate falsified information. \n",
    "\n",
    "\"Fake News\" is a term used to describe fabricated news or propaganda c\n",
    "ontaining\n",
    "misinformation that is communicated through traditional media channels like print, and\n",
    "television as well as non-traditional media channels like social media. Fake news is as old as the news industry itself—misinformation, propaganda, hoaxes and satire have long been in existence.\n",
    "\n",
    "However social media is a relatively new invention that offers a setting for the general population to share their opinions and views in a raw and un-edited fashion. News articles hosted or shared on social media platforms have more views compared to direct views from the media outlets’ platform. Research that studied the velocity of fake news concluded that tweets containing false information reach people on Twitter six times faster than truthful tweets. \n",
    "\n",
    "Today anybody can publish anything credible or not that can be consumed by the World Wide Web. Due to this, people can be deceived intentionally or unintentionally and may not think before sharing such types of news to the far ends of the world. \n",
    "\n",
    "Technologies such as Natural Language Processing (NLP) tools offer great promise for building systems which could automatically detect fake news. Natural-language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, and how to program computers to process large amounts of natural language data\n",
    "\n",
    "NLP combines computational linguistics—the computational modelling of natural language—with statistical, machine learning, and deep learning models. Together, these technologies enable computers to process human language in the form of text or voice data and to ‘understand’ its full meaning, complete with the speaker or writer’s intent and sentiment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "stem_sentences=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    stem_sentences.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In today ’ highli digit world , onlin content news websit , video social media becom decid factor mind gener public come form opinion issu .', 'As peopl begin reli internet everi trivial task , necessari make sure misinform fake news detect filter order reduc neg effect .', 'In recent time , outbreak covid-19 viru shown fake news real issu harm potenti spread faster viru .', 'It abil manipul peopl ’ percept wide use sever politician influenc larg group peopl even caus social conflict order fulfil person agenda .', 'these problem make necessari elimin falsifi inform .', \"`` fake new '' term use describ fabric news propaganda contain misinform commun tradit media channel like print , televis well non-tradit media channel like social media .\", 'fake news old news industri itself—misinform , propaganda , hoax satir long exist .', 'howev social media rel new invent offer set gener popul share opinion view raw un-edit fashion .', 'new articl host share social media platform view compar direct view media outlet ’ platform .', 'research studi veloc fake news conclud tweet contain fals inform reach peopl twitter six time faster truth tweet .', 'today anybodi publish anyth credibl consum world wide web .', 'due , peopl deceiv intent unintent may think share type news far end world .', 'technolog natur languag process ( nlp ) tool offer great promis build system could automat detect fake news .', 'natural-languag process ( nlp ) area comput scienc artifici intellig concern interact comput human ( natur ) languag , program comput process larg amount natur languag data nlp combin comput linguistics—th comput model natur language—with statist , machin learn , deep learn model .', 'togeth , technolog enabl comput process human languag form text voic data ‘ understand ’ full mean , complet speaker writer ’ intent sentiment .']\n"
     ]
    }
   ],
   "source": [
    "print(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "lem_sentences=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    lem_sentences.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In today ’ highly digital world , online content news website , video social medium become deciding factor mind general public come forming opinion issue .', 'As people begin rely internet every trivial task , necessary make sure misinformation fake news detected filtered order reduce negative effect .', 'In recent time , outbreak Covid-19 virus shown fake news real issue harmful potential spreading faster virus .', 'It ability manipulate people ’ perception widely used several politician influence large group people even cause social conflict order fulfill personal agenda .', 'These problem make necessary eliminate falsified information .', \"`` Fake News '' term used describe fabricated news propaganda containing misinformation communicated traditional medium channel like print , television well non-traditional medium channel like social medium .\", 'Fake news old news industry itself—misinformation , propaganda , hoax satire long existence .', 'However social medium relatively new invention offer setting general population share opinion view raw un-edited fashion .', 'News article hosted shared social medium platform view compared direct view medium outlet ’ platform .', 'Research studied velocity fake news concluded tweet containing false information reach people Twitter six time faster truthful tweet .', 'Today anybody publish anything credible consumed World Wide Web .', 'Due , people deceived intentionally unintentionally may think sharing type news far end world .', 'Technologies Natural Language Processing ( NLP ) tool offer great promise building system could automatically detect fake news .', 'Natural-language processing ( NLP ) area computer science artificial intelligence concerned interaction computer human ( natural ) language , program computer process large amount natural language data NLP combine computational linguistics—the computational modelling natural language—with statistical , machine learning , deep learning model .', 'Together , technology enable computer process human language form text voice data ‘ understand ’ full meaning , complete speaker writer ’ intent sentiment .']\n"
     ]
    }
   ],
   "source": [
    "print(lem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the texts\n",
    "import re\n",
    "\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "cv=CountVectorizer()\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=TfidfVectorizer()\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.18392207 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.13103133 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.23993522]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
